<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Navdeep Gill</title>
    <link rel="stylesheet" href="style.css">
    <!-- Add MathJax script for LaTeX rendering -->
    <script type="text/javascript" async
        src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.7/MathJax.js?config=TeX-MML-AM_CHTML">
    </script>
    <style>
        .header-container {
            display: flex;
            align-items: center;
        }
        .header-container img {
            width: 100px; /* Adjust size as needed */
            height: 100px;
            border-radius: 50%;
            margin-right: 20px;
        }
        .header-container .contact-info {
            margin-top: 5px;
            font-size: 0.9em;
        }
        .header-container .contact-info p {
            margin: 3px 0;
        }
    </style>
</head>
<body>
    <header>
        <div class="container header-container">
            <img src="images/navdeep.jpg" alt="Navdeep Gill">
            <div>
                <h1>Navdeep Gill</h1>
                <div class="contact-info">
                    <div class="email-cv-container">
                        <p><strong>Email:</strong> mr.navdeepgill@gmail.com</p>
                        <a href="files/cv.pdf" target="_blank">
                            <button class="cv-button">CV (as of 2024)</button>
                        </a>
                    </div>
                </div>
            </div>
        </div>
    </header>
    
    
    <section class="external-links">
        <h2>External Links</h2>
        <ul>
            <li><strong>Publications:</strong> <a href="https://scholar.google.com/citations?hl=en&user=g6dQcNUAAAAJ&view_op=list_works&sortby=pubdate" target="_blank">Google Scholar</a></li>
            <li><strong>GitHub:</strong> <a href="https://github.com/navdeep-G" target="_blank">github.com/navdeep-G</a></li>
            <li><strong>LinkedIn:</strong> <a href="https://www.linkedin.com/in/navdeep-gill-b1729456" target="_blank">linkedin.com/in/navdeep-gill</a></li>
        </ul>
    </section>
    

    <main>
        <section id="bio">
            <div class="container">
                <p>Navdeep Gill is a Staff Product Manager for Responsible AI at <a href="https://www.servicenow.com/" target="_blank">ServiceNow</a>, where he contributes to leading initiatives to define and implement strategies for AI Governance and Responsible AI across the organization, collaborating with cross-functional teams to ensure AI systems meet the highest standards of transparency, fairness, and accountability.</p>
                
                <p>Previously, Navdeep spent nearly a decade at <a href="https://www.h2o.ai/" target="_blank">H2O.ai</a>, where he held roles as Lead Data Scientist, Senior Software Engineer, and Software Engineer. As Lead Data Scientist, he led engineering and data science initiatives to create innovative solutions in AI Governance and Responsible AI. As a Senior Software Engineer, he spearheaded efforts to enhance machine learning interpretability in Driverless.ai, H2O.ai's flagship AutoML platform. Earlier, as a Software Engineer, he played an integral role in advancing H2O AutoML, collaborated on the development of H2O4GPU to optimize GPU-based machine learning tasks, and contributed to enhancing H2O-3, a distributed machine learning platform for big data environments.</p>
                
                <p>Earlier in his career, Navdeep worked as a Business Intelligence Engineer at <a href="https://www.cisco.com/" target="_blank">Cisco</a>, where he developed data analytics and machine learning solutions to enhance operational efficiency in contact centers. Before that, he was an Analytic Science Consultant at <a href="https://www.fico.com/en" target="_blank">FICO</a>, building machine learning models for credit risk management across originations, customer management, and collections.</p>
                
                <p>Before transitioning into the tech industry, Navdeep conducted research on neural mechanisms of memory and attention at the <a href="https://www.ucsf.edu/" target="_blank">University of California, San Francisco</a>, focusing on their changes in normal aging and dementia, with an emphasis on therapeutic interventions to mitigate deficits. He also studied how the brain perceives depth in 3D space at the <a href="https://www.ski.org/" target="_blank">Smith-Kettlewell Eye Research Institute</a>, examining the effects of brain injuries on depth perception and eye movement control.</p>
                
                <p>Navdeep has contributed to the fields of Responsible AI and AI Governance through academic publications, white papers, and technical blogs.</p>
            </div>
        </section>                
        <section id="publications" class="publications">
            <div class="container">
                <h2>Publications</h2>
                <ul>
                    <li>Gill, N., Zhang, S. (2023). <a href="https://h2o.ai/resources/ebook/Guidelines-for-Effective-AI-Governance-with-Applications/" target="_blank">Guidelines for Effective AI Governance with Applications in H2O AI Cloud</a>. H2O.ai.</li>
                    <li>Gill, N., Mathur, A., Conde, M. (2022). <a href="https://arxiv.org/abs/2211.13130" target="_blank">A Brief Overview of AI Governance in Responsible Machine Learning Systems</a>. In NeurIPS Workshop on Trustworthy and Socially Responsible Machine Learning (TSRML).</li>
                    <li>Hall, P., Gill, N., Cox, B. (2020). <a href="https://www.oreilly.com/library/view/responsible-machine-learning/9781492090878/" target="_blank">Responsible Machine Learning: Actionable Strategies for Mitigating Risk and Driving Adoption</a>. Sebastopol, CA, USA: O’Reilly Media, Inc.</li>
                    <li>Gill, N., Hall, P., Montgomery, K., Schmidt, N. (2020). <a href="https://www.mdpi.com/2078-2489/11/3/137" target="_blank">A Responsible Machine Learning Workflow with Focus on Interpretable Models, Post-hoc Explanation, and Discrimination Testing</a>. Information, 11(3):137.</li>
                    <li>Hall, P., Gill, N. (2019). <a href="https://www.oreilly.com/library/view/an-introduction-to/9781098115487/?_gl=1*16hyutm*_ga*MTMwMzczMTE0Ny4xNzM1NzUwMzk5*_ga_092EL089CH*MTczNTc1MDM5OS4xLjEuMTczNTc1MDgxMy4xMy4wLjA." target="_blank">An Introduction to Machine Learning Interpretability, Second Edition: An Applied Perspective on Fairness, Accountability, Transparency, and Explainable AI</a>. Sebastopol, CA, USA: O’Reilly Media, Inc.</li>
                    <li>Hall, P., Gill, N., Schmidt, N. (2019). <a href="https://arxiv.org/abs/1906.03533" target="_blank">Proposed Guidelines for the Responsible Use of Explainable Machine Learning</a>. In NeurIPS Workshop on Robust AI in Financial Services.</li>
                    <li>Hall, P., Gill, N., Meng, L. (2018). <a href="https://www.oreilly.com/ideas/testing-machine-learning-interpretability-techniques" target="_blank">Testing Machine Learning Explanation Techniques</a>. Newton, MA, USA: O’Reilly Media.</li>
                    <li>Hall, P., Gill, N. (2018). <a href="https://www.oreilly.com/library/view/an-introduction-to/9781492033158/" target="_blank">An Introduction to Machine Learning Interpretability: An Applied Perspective on Fairness, Accountability, Transparency, and Explainable AI</a>. Newton, MA, USA: O’Reilly Media, Inc.</li>
                    <li>Hall, P., Gill, N., Kurka, M., Phan, W. (2017). <a href="https://docs.h2o.ai/driverless-ai/latest-stable/docs/booklets/MLIBooklet.pdf" target="_blank">Machine Learning Interpretability with H2O Driverless AI</a>. H2O.ai.</li>
                    <li>Voytek, B., Samaha, J., Rolle, C. E., Greenberg, Z., Gill, N., Porat, S. (2017). <a href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC7474864/" target="_blank">Preparatory Encoding of the Fine Scale of Human Spatial Attention</a>. Journal of Cognitive Neuroscience, 29, 1302–1310.</li>
                    <li>Tyler, C.W., Elsaid, A.M., Likova, L.T., Gill, N., & Nicholas, S.C. (2012). <a href="https://jov.arvojournals.org/article.aspx?articleid=2192087" target="_blank">Analysis of Human Vergence Dynamics</a>. Journal of Vision, 12(11):21; doi:10.1167/12.11.21.</li>
                </ul>
            </div>
        </section>        
        <section id="conferences" class="conferences">
            <div class="container">
                <h2>Conference Presentations</h2>
                <ul>
                    <li>Gill, N., Montgomery, K. (2024). Interpretability for Generative AI. H2O GenAI Day, Atlanta, GA, January 23.</li>
                    <li>Gill, N. (2023). Guardrails for LLMs. H2O Open Source GenAI World, San Francisco, CA, November 7.</li>
                    <li>Gill, N., Mathur, A. (2022). Incorporating AI Governance to Increase Adoption in Business Applications. MLOps World 2022, New York, NY, July 14.</li>
                    <li>Gill, N., Tanco, M. (2021). Security Audits for Machine Learning Attacks. MLOps World 2021, June 16.</li>
                    <li>Gill, N. (2021). Training Understandable, Fair, Trustable and Accurate Predictive Modeling Systems. Duke Machine Learning Day, Durham, North Carolina, March 27.</li>
                    <li>Gill, N. (2019). Human Centered Machine Learning. Artificial Intelligence Conference, San Jose, CA, September 11.</li>
                    <li>Gill, N. (2019). Interpretable Machine Learning Using rsparkling. Symposium on Data Science and Statistics, Bellevue, Washington, May 31.</li>
                    <li>Gill, N. (2019). Practical Machine Learning Interpretability Techniques. GPU Technology Conference, San Jose, CA, March 21.</li>
                    <li>Gill, N. (2018). Distributed Machine Learning with H2O. Joint Statistical Meeting, Vancouver, Canada, August 1.</li>
                    <li>Gill, N. (2018). H2O AutoML. Symposium on Data Science and Statistics, Reston, Virginia, May 16.</li>
                    <li>Hall, P., Gill, N., Chan, M. (2018). Practical Techniques for Interpreting Machine Learning Models: Introductory Open Source Examples using Python, H2O and XGBoost. 1st ACM Conference on Fairness, Accountability, and Transparency, New York City, February 23-24.</li>
                    <li>Gill, N., Hall, P., Chan, M. (2017). Driverless AI Hands-On Focused on Machine Learning Interpretability. H2O World, Mountain View, CA, December 11.</li>
                    <li>Gill, N. (2017). From R Script to Production using rsparkling. Spark Summit, San Francisco, CA, June 14.</li>
                    <li>Gill, N. (2016). Scalable Machine Learning in R with H2O. useR Conference, Stanford, Palo Alto, CA, July 11.</li>
                    <li>Voytek, B., Porat, S., Chamberlain, J., Balthazor, J., Greenberg, Z., Gill, N., Gazzaley, A. (2013). Examining the efficacy of the iPad and Xbox Kinect for cognitive science research. 2nd Annual Meeting of the Entertainment Software and Cognitive Neurotherapeutics Society, Los Angeles, California, March 15-17.</li>
                    <li>Greenberg, Z., Gill, N., Porat, S., Samaha, J., Kader, T., Voytek, B., & Gazzaley, A. (2013). Increased visual cortical noise decreases cued visual attention distribution. 20th Annual Meeting of the Cognitive Neuroscience Society, San Francisco, California, April 13-16.</li>
                    <li>Tyler, C.W., Gill, N., & Nicholas, S. (2012). Hysteresis in Stereoscopic Surface Interpolation: A New Paradigm. 12th Annual Meeting of the Vision Sciences Society, Naples, Florida, May 11-16.</li>
                    <li>Gill, N., Fencsik, D. (2012). Effects of Disruptions on Multiple Object Tracking. California Cognitive Science Conference, UC Berkeley, California, April 28.</li>
                    <li>Gill, N., Fencsik, D. (2011). Effects of Distractions on Recovery Time. Psychology Undergraduate Research Conference, UC Berkeley, California, May 1.</li>
                </ul>
            </div>
        </section>
        <section id="patents" class="patents">
            <div class="container">
                <h2>Patents</h2>
                <ul>
                    <li>Chan, M., Gill, N., & Hall, P. (2024). <a href="https://patents.justia.com/patent/11922283" target="_blank">Model Interpretation</a>. U.S. Patent No. 11,922,283. Washington, DC: U.S. Patent and Trademark Office.</li>
                    <li>Chan, M., Gill, N., & Hall, P. (2022). <a href="https://patents.justia.com/patent/11386342" target="_blank">Model Interpretation</a>. U.S. Patent No. 11,386,342. Washington, DC: U.S. Patent and Trademark Office.</li>
                </ul>
            </div>
        </section>
               
    </main>
</body>
</html>
